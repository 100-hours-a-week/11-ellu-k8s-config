apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
  namespace: looper-prod
  labels:
    app: kafka
spec:
  serviceName: kafka-headless
  replicas: 1
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      initContainers:
        - name: fix-permissions
          image: busybox:1.35
          command: ['sh', '-c']
          args:
            - |
              mkdir -p /var/lib/kafka/data /var/log/kafka
              chown -R 1000:1000 /var/lib/kafka/data
              chmod -R 755 /var/lib/kafka/data
              chown -R 1000:1000 /var/log/kafka
              chmod -R 755 /var/log/kafka
          volumeMounts:
            - name: kafka-data
              mountPath: /var/lib/kafka/data
            - name: kafka-logs
              mountPath: /var/log/kafka
          securityContext:
            runAsUser: 0
        - name: wait-for-zookeeper
          image: busybox:1.35
          command: ['sh', '-c']
          args:
            - |
              until nc -z zookeeper.looper-prod.svc.cluster.local 2181; do
                echo "Waiting for zookeeper..."
                sleep 2
              done
              echo "Zookeeper is ready!"
        - name: setup-kafka-metadata
          image: confluentinc/cp-kafka:7.9.0
          command: ['sh', '-c']
          args:
            - |
              if [ ! -f /var/lib/kafka/data/meta.properties ]; then
                echo "Creating meta.properties for fresh Kafka installation..."
                mkdir -p /var/lib/kafka/data
                
                CLUSTER_ID=$(kafka-storage random-uuid)
                echo "Generated cluster ID: $CLUSTER_ID"
                
                kafka-storage format \
                  --config /etc/kafka/kafka.properties \
                  --cluster-id "$CLUSTER_ID" \
                  --ignore-formatted
                
                chown -R 1000:1000 /var/lib/kafka/data
              else
                echo "Using existing Kafka data directory"
                ls -la /var/lib/kafka/data/
              fi
          volumeMounts:
            - name: kafka-data
              mountPath: /var/lib/kafka/data
            - name: kafka-logs
              mountPath: /var/log/kafka
            - name: kafka-config
              mountPath: /etc/kafka
          securityContext:
            runAsUser: 0
          env:
            - name: KAFKA_ZOOKEEPER_CONNECT
              value: "zookeeper.looper-prod.svc.cluster.local:2181"
            - name: KAFKA_LISTENERS
              value: "PLAINTEXT://0.0.0.0:29092"
            - name: KAFKA_ADVERTISED_LISTENERS
              value: "PLAINTEXT://kafka-0.kafka-headless.looper-prod.svc.cluster.local:29092"
            - name: KAFKA_BROKER_ID
              value: "0"
            - name: KAFKA_LOG_DIRS
              value: "/var/lib/kafka/data"
      containers:
        - name: kafka
          image: confluentinc/cp-kafka:7.9.0
          ports:
            - containerPort: 29092
              name: internal
            - containerPort: 9092
              name: external
          env:
            - name: KAFKA_BROKER_ID
              value: "0"
            - name: KAFKA_ZOOKEEPER_CONNECT
              value: "zookeeper.looper-prod.svc.cluster.local:2181"
            - name: KAFKA_LISTENERS
              value: "PLAINTEXT://0.0.0.0:29092"
            - name: KAFKA_ADVERTISED_LISTENERS
              value: "PLAINTEXT://kafka-0.kafka-headless.looper-prod.svc.cluster.local:29092"
            - name: KAFKA_LISTENER_SECURITY_PROTOCOL_MAP
              value: "PLAINTEXT:PLAINTEXT"
            - name: KAFKA_INTER_BROKER_LISTENER_NAME
              value: "PLAINTEXT"
            - name: KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR
              value: "1"
            - name: KAFKA_TRANSACTION_STATE_LOG_MIN_ISR
              value: "1"
            - name: KAFKA_AUTO_CREATE_TOPICS_ENABLE
              value: "true"
            - name: KAFKA_LOG_DIRS
              value: "/var/lib/kafka/data"
            - name: KAFKA_LOG4J_ROOT_LOGLEVEL
              value: "WARN"
            - name: KAFKA_LOG_RETENTION_HOURS
              value: "168"
            - name: KAFKA_LOG_SEGMENT_BYTES
              value: "1073741824"
            - name: KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS
              value: "300000"
            - name: KAFKA_ZOOKEEPER_CONNECTION_TIMEOUT_MS
              value: "6000"
          volumeMounts:
            - name: kafka-data
              mountPath: /var/lib/kafka/data
            - name: kafka-logs
              mountPath: /var/log/kafka
            - name: kafka-config
              mountPath: /etc/kafka
          securityContext:
            runAsUser: 1000
            runAsGroup: 1000
            fsGroup: 1000
          resources:
            requests:
              cpu: 250m
              memory: 1Gi
            limits:
              cpu: 500m
              memory: 1Gi
          readinessProbe:
            tcpSocket:
              port: 29092
            initialDelaySeconds: 30
            periodSeconds: 10
          livenessProbe:
            tcpSocket:
              port: 29092
            initialDelaySeconds: 60
            periodSeconds: 30
      volumes:
        - name: kafka-config
          configMap:
            name: kafka-config
  volumeClaimTemplates:
    - metadata:
        name: kafka-data
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: ebs-sc
        resources:
          requests:
            storage: 10Gi
    - metadata:
        name: kafka-logs
      spec:
        accessModes: ["ReadWriteOnce"]
        storageClassName: ebs-sc
        resources:
          requests:
            storage: 2Gi